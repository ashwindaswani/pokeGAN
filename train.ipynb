{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bit8a7e00cc0ecb44c384611e7cebb4c8e8",
   "display_name": "Python 3.8.5 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image               # to load images\n",
    "from IPython.display import display # to display images\n",
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<PIL.Image.Image image mode=RGB size=64x64 at 0x7FCCFCADBCD0>",
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "\n",
    "abra = Image.open('dataset/Abra/2eb2a528f9a247358452b3c740df69a0.jpg')\n",
    "abra = abra.resize((64,64))\n",
    "display(abra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim=64\n",
    "height=64\n",
    "width=64\n",
    "channels=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 64)]              0         \n_________________________________________________________________\ndense (Dense)                (None, 131072)            8519680   \n_________________________________________________________________\nleaky_re_lu (LeakyReLU)      (None, 131072)            0         \n_________________________________________________________________\nreshape (Reshape)            (None, 32, 32, 128)       0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, 32, 32, 256)       819456    \n_________________________________________________________________\nleaky_re_lu_1 (LeakyReLU)    (None, 32, 32, 256)       0         \n_________________________________________________________________\nconv2d_transpose (Conv2DTran (None, 64, 64, 256)       1048832   \n_________________________________________________________________\nleaky_re_lu_2 (LeakyReLU)    (None, 64, 64, 256)       0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 64, 64, 256)       1638656   \n_________________________________________________________________\nleaky_re_lu_3 (LeakyReLU)    (None, 64, 64, 256)       0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 64, 64, 3)         37635     \n=================================================================\nTotal params: 12,064,259\nTrainable params: 12,064,259\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator_input=keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(128*32*32)(generator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Reshape((32,32,128))(x)\n",
    "\n",
    "x = layers.Conv2D(256, 5, padding = 'same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2DTranspose(256, 4, strides = 2, padding = 'same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(256, 5, padding = 'same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "# x = layers.Conv2D(256, 5, padding = 'same')(x)\n",
    "# x = layers.LeakyReLU()(x)\n",
    "# x = layers.Dropout(0.4)(x)\n",
    "x = layers.Conv2D(channels, 7, activation = 'tanh', padding= 'same')(x)\n",
    "generator = keras.models.Model(generator_input, x)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_3 (InputLayer)         [(None, 64, 64, 3)]       0         \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 62, 62, 128)       3584      \n_________________________________________________________________\nleaky_re_lu_7 (LeakyReLU)    (None, 62, 62, 128)       0         \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 30, 30, 128)       262272    \n_________________________________________________________________\nleaky_re_lu_8 (LeakyReLU)    (None, 30, 30, 128)       0         \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 14, 14, 128)       262272    \n_________________________________________________________________\nleaky_re_lu_9 (LeakyReLU)    (None, 14, 14, 128)       0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 14, 14, 128)       0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 14, 14, 1)         129       \n=================================================================\nTotal params: 528,257\nTrainable params: 528,257\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator_input = keras.Input(shape=(height,width,channels))\n",
    "x = layers.Conv2D(128, 3)(discriminator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, 4, strides = 2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, 4, strides = 2)(x)\n",
    "# x = layers.LeakyReLU()(x)\n",
    "# x = layers.Conv2D(128, 4, strides = 2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "x = layers.Dense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "discrimnator = keras.models.Model(discriminator_input, x)\n",
    "discrimnator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_optimizer = keras.optimizers.RMSprop(learning_rate= 0.0008, clipvalue= 1, decay = 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrimnator.compile(optimizer= discriminator_optimizer, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrimnator.trainable = False\n",
    "gan_input = keras.Input(shape= (latent_dim,))\n",
    "gan_output = discrimnator(generator(gan_input))\n",
    "gan = keras.models.Model(gan_input, gan_output)\n",
    "gan_optimzer = keras.optimizers.RMSprop(learning_rate= 0.0004, clipvalue= 1, decay= 1e-8)\n",
    "gan.compile(optimizer= gan_optimzer, loss = 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "OpenCV(4.5.1) /tmp/pip-req-build-ms668fyv/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "OpenCV(4.5.1) /tmp/pip-req-build-ms668fyv/opencv/modules/imgproc/src/resize.cpp:4051: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "for f in os.listdir('dataset'):\n",
    "    for p in os.listdir('dataset/' + f):\n",
    "        if not p.endswith('svg'):\n",
    "            # a = Image.open('dataset/' + f + '/' + p)\n",
    "            a = cgitv2.imread('dataset/' + f + '/' + p)\n",
    "            try:\n",
    "                a = cv2.resize(a,(64,64))\n",
    "                x.append(a)\n",
    "            except Exception as e:\n",
    "                print(str(f + \"  ==\" + p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10665"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "  len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'<bound method Image.tobytes of <PIL.Image.Image image mode=RGB size=64x64 at 0x7FCCB13DA460>>'"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}